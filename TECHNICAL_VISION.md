# Visi√≥n T√©cnica: Jota - El Cerebro Centralizado

Este documento define la arquitectura, los est√°ndares y la hoja de ruta para **Jota**, un ecosistema de asistente virtual dise√±ado para la persistencia, la conciencia contextual y la eficiencia.

---

## 1. Resumen de Infraestructura

Jota funciona como una **arquitectura backend distribuida** orquestada centralmente.

### M√≥dulos N√∫cleo (Core)
* **Jota-Orchestrator (Python/FastAPI):** El centro nervioso. Act√∫a como un **Enrutador Cognitivo** que gestiona la l√≥gica de negocio, la memoria y la orquestaci√≥n.
    - **Estado Actual**: Integrado con Inference Center (WebSocket) y l√≥gica de sesiones as√≠ncrona.
* **Inference Center (C++):** Motor de inferencia remoto.
* **Transcription API (C++):** Servidor de streaming STT.

---

## 2. Arquitectura de Orquestaci√≥n

### Flujo de Inferencia End-to-End (Implementado)
El orquestador act√∫a como un proxy inteligente y gestor de estado:

1. **Entrada de Usuario**: Recibida v√≠a WebSocket (`/ws/chat/{user_id}`) o REST.
2. **Controlador (`JotaController`)**:
   - Recupera el historial de **Memoria**.
   - Invoca al cliente de inferencia.
3. **Cliente de Inferencia (`InferenceClient`)**:
   - Gestiona la conexi√≥n WebSocket persistente con el motor C++.
   - **Stateless**: Delega el estado de la sesi√≥n en `MemoryManager` (JotaDB).
   - Autentica (`auth`) y crea sesiones (`create_session`) bajo demanda.
   - Despacha streams de tokens concurrentes usando colas as√≠ncronas (`asyncio.Queue`).
   - Soporta **Exponential Backoff** para reconexi√≥n autom√°tica.
4. **Streaming**: Los tokens fluyen en tiempo real de `InferenceCenter` -> `Orchestrator` -> `User` sin bloqueo.

### Gesti√≥n de Memoria Unificada (JotaDB)
* **Persistencia Externa:** El orquestador no almacena estado. Todo reside en JotaDB.
* **Contexto de Sesi√≥n:** Mapeo din√°mico `conversaci√≥n_id` <-> `inference_session_id` gestionado por JotaDB.
* **Deep Health Check:** Monitoreo activo de conexiones a JotaDB y Motor de Inferencia (`/health`).

---

## 3. Plan de Implementaci√≥n

### Fase 1: El Puente de Datos (‚úÖ Completado)
* [x] Configurar `InferenceClient` con protocolo as√≠ncrono y autenticaci√≥n.
* [x] Implementar streaming de tokens en tiempo real (Async Generators).
* [x] API WebSocket para clientes finales.

### Fase 2: L√≥gica de Decisi√≥n y Routing (üöß En Progreso)
* Desarrollar el `IntentRouter` para distinguir comandos de conversaci√≥n.
* Estructura de "Tool Calling" para dom√≥tica.

### Fase 3: Interfaz y Observabilidad
* Web Dashboard para control y m√©tricas.

---

## 4. Est√°ndares
* **WebSockets (WS/WSS):** Est√°ndar comunicaci√≥n streaming.
* **AsyncIO:** N√∫cleo de concurrencia en Python para manejar I/O intenso sin bloquear.
* **Seguridad:** Autenticaci√≥n por Tokens en capa de transporte.